{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e639d5cd-13ba-421b-aa6c-2a88511b59e9",
   "metadata": {},
   "source": [
    "<h5><b>Assignment 05:</b></h5>\n",
    " <h5><b>Event Extraction from Syntactic Dependencies</b></h5>\n",
    " <p>Shashikala Kankanamge (6648398)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8f3db-4a60-4488-b837-cc8a26f52ac5",
   "metadata": {},
   "source": [
    "<b> Task 1: Getting the Model, First Parse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d7e4d6-a965-4c2b-9e4f-bca68c35214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea43ffb4-f4b1-41e8-8cc1-1466d2932a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b246bb6f-95ae-4f25-ac41-f4420bd01627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee7eb8a-691c-406e-b3b5-cb6a23b3d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e458ecf-6424-4090-8c8b-d19024b4f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201845\n"
     ]
    }
   ],
   "source": [
    "text_content = open(\"azuela1920_los-de-abajo.txt\", \"r\", \n",
    "                    encoding=\"utf-8\").read()\n",
    "print(len(text_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df21107-e553-4f49-a0d8-9b48816cafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Total tokens: 45720\n",
      "Total sentences: 1928\n"
     ]
    }
   ],
   "source": [
    "doc =model(text_content)\n",
    "print(type(doc))\n",
    "print(f\"Total tokens: {len(doc)}\")\n",
    "print(f\"Total sentences: {len(list(doc.sents))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a614a7f3-175d-445a-a7dd-e765f85d6b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Los de Abajo\\nMariano Azuela\\n\\nPRIMERA PARTE\\n=============\\n\\nI\\n—Te digo que no es un animal... Oye cómo ladra el Palomo... Debe ser algún cristiano...\\nLa mujer fijaba sus pupilas en la oscuridad de la sierra.',\n",
       " '— ¿Y que fueran siendo federales?',\n",
       " '—repuso un hombre que, en cuclillas, yantaba en un rincón, una\\ncazuela en la diestra y tres tortillas en taco en la otra mano.',\n",
       " 'La mujer no le contestó; sus sentidos estaban puestos fuera de la casuca.',\n",
       " 'Se oyó un ruido de pesuñas en el pedregal cercano, y el Palomo ladró con más rabia.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the sentence spans\n",
    "  \n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9417b04c-fdbe-417a-a342-7c573fcde74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract and save file to :  sentences_with_newLine.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_with_newLine = \"sentences_with_newLine.txt\"\n",
    "with open(output_file_with_newLine, \"w\",\n",
    "          encoding=\"utf-8\") as output_file:\n",
    "    for sentence in sentences:\n",
    "        output_file.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Extract and save file to :  {output_file_with_newLine}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2c2e4-f5d4-4a68-9419-42eb7041ae87",
   "metadata": {},
   "source": [
    "<b>Task 2: Understanding Sentence Segmentation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61c4845-7409-4ea2-8e6d-d5d927615a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract and save file to :  sentences_with_space.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_with_space = \"sentences_with_space.txt\"\n",
    "with open(output_file_with_space, \"w\", \n",
    "          encoding=\"utf-8\") as output_file:\n",
    "    for sentence in sentences:\n",
    "        # print(sentence)\n",
    "        output_file.write(sentence + \" \")\n",
    "\n",
    "print(f\"Extract and save file to :  {output_file_with_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa38ede2-df4d-4adf-b249-ed71f1544eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence Count (with newlines): 1928\n",
      "Original Sentence Count (with newlines): 3951\n",
      "Sentence Count (with spaces): 2024\n"
     ]
    }
   ],
   "source": [
    "with open(\"./sentences_with_newLine.txt\", \"r\", \n",
    "          encoding=\"utf-8\") as file1:\n",
    "    sentence_newLine = file1.readlines()\n",
    "\n",
    "with open(\"./sentences_with_space.txt\", \"r\",\n",
    "          encoding=\"utf-8\") as file2:\n",
    "    sentence_with_space = file2.readlines()\n",
    "\n",
    "print(f\"Original Sentence Count (with newlines): {len(sentences)}\")\n",
    "print(f\"Original Sentence Count (with newlines): {len(sentence_newLine)}\")\n",
    "print(f\"Sentence Count (with spaces): {len(sentence_with_space)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570ea15-f79e-4c69-8527-c26a88b1186d",
   "metadata": {},
   "source": [
    "<b>Task 3: Extracting Verb-Subject Pairs</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646c7469-3371-4d83-be26-5e5425634887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pair length : 2135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ladrar', 'Palomo'),\n",
       " ('fijar', 'mujer'),\n",
       " ('reponer', 'hombre'),\n",
       " ('yantar', 'que'),\n",
       " ('contestar', 'mujer'),\n",
       " ('oir', 'ruido'),\n",
       " ('acabar', 'hombre'),\n",
       " ('acercar', 'cántaro'),\n",
       " ('pronunciar', 'él'),\n",
       " ('alumbrar', 'cuartito')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_subject_pairs = []\n",
    "for token in doc:\n",
    "    if token.pos_ == \"VERB\" and any(child.dep_ == \"nsubj\" for \n",
    "                                    child in token.children):\n",
    "        subject = [child for child in token.children if \n",
    "                   child.dep_ == \"nsubj\"][0]\n",
    "        verb_subject_pairs.append((token.lemma_, subject.lemma_))\n",
    "\n",
    "print('Total pair length :',len(verb_subject_pairs))\n",
    "verb_subject_pairs[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f39c9-2925-4cdd-ad05-0e4333fbaeac",
   "metadata": {},
   "source": [
    "<b>Task 4: From Actions to Characters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c3ccd2-6533-4198-a08a-4968e1a7ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decir', 126),\n",
       " ('tener', 53),\n",
       " ('hacer', 50),\n",
       " ('dar', 45),\n",
       " ('saber', 44),\n",
       " ('querer', 38),\n",
       " ('venir', 36),\n",
       " ('ir', 34),\n",
       " ('dejar', 28),\n",
       " ('volver', 28)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "verb_counter = Counter(verb for verb, subject in \n",
    "                       verb_subject_pairs)\n",
    "most_common_verbs = verb_counter.most_common(10)\n",
    "most_common_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a7fde-b857-4cc8-80df-ef9c254ada6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182d0494-1cf1-4a6b-87d5-ab29f1cb702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Common Subjects for 'gritar':\n",
      "Manteca: 2\n",
      "Demetrio: 2\n",
      "María: 2\n",
      "\n",
      "Most Common Subjects for 'preguntar':\n",
      "Pancracio: 4\n",
      "Anastasio: 3\n",
      "Demetrio: 3\n",
      "\n",
      "Most Common Subjects for 'responder':\n",
      "Demetrio: 3\n",
      "Pancracio: 3\n",
      "Carranzo: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "verbs_of_interest = [\"gritar\", \"preguntar\", \"responder\"]\n",
    "subjects_by_verb = {verb: [] for verb in verbs_of_interest}\n",
    "\n",
    "for verb, subject in verb_subject_pairs:\n",
    "    if verb in verbs_of_interest:\n",
    "        subjects_by_verb[verb].append(subject)\n",
    "\n",
    "for verb, subjects in subjects_by_verb.items():\n",
    "    subject_counts = Counter(subjects)\n",
    "    print(f\"\\nMost Common Subjects for '{verb}':\")\n",
    "    for subject, count in subject_counts.most_common(3):  # Top 3\n",
    "        print(f\"{subject}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a9466-6d32-4fbe-bae6-5678569bb1a9",
   "metadata": {},
   "source": [
    "<li>Who shouts the Most: Manteca, Demetrio, and María.</li>\n",
    "<li>Who asks the Most Questions: Pancracio</li>\n",
    "<li>Who answers the Most: Demetrio & Pancracio </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc397e-8504-4590-b6a9-400a6df7ceca",
   "metadata": {},
   "source": [
    "<b>Task 5: Foreground and Background Events</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38069cd8-5eca-4b05-94c1-fa70eacd34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_pairs = []\n",
    "background_pairs = []\n",
    "\n",
    "for verb, subject in verb_subject_pairs:\n",
    "    verb_token = next((token for token in doc if token.lemma_ == verb), None)\n",
    "    \n",
    "    subject_token = next((token for token in doc if token.lemma_ == subject), None)\n",
    "    \n",
    "    if verb_token and verb_token.pos_ == \"VERB\" and \"Tense=Past\" in verb_token.morph:\n",
    "        foreground_pairs.append((verb, subject))\n",
    "    \n",
    "    if verb_token and verb_token.pos_ == \"VERB\" and \"Tense=Imp\" in verb_token.morph:\n",
    "        background_pairs.append((verb, subject))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd597fb6-115a-4223-a84a-84d89bbe2559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reponer', 'hombre'),\n",
       " ('contestar', 'mujer'),\n",
       " ('oir', 'ruido'),\n",
       " ('acabar', 'hombre'),\n",
       " ('acercar', 'cántaro')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreground_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c455da25-179e-4611-a049-477b1ea9f3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fijar', 'mujer'),\n",
       " ('yantar', 'que'),\n",
       " ('alumbrar', 'cuartito'),\n",
       " ('servir', 'que'),\n",
       " ('dormir', 'hilacha')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f97b9e8c-486a-4f7f-a43f-e9424b48f80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background_verbs: 246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "foreground_verbs = Counter(verb for verb, subject in foreground_pairs)\n",
    "background_verbs = Counter(verb for verb, subject in background_pairs)\n",
    "\n",
    "\n",
    "\n",
    "print(\"background_verbs:\", len(foreground_verbs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ca9fad8-9771-4523-912a-1a32763b6aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foreground_verbs: 246\n"
     ]
    }
   ],
   "source": [
    "print(\"foreground_verbs:\", len(foreground_verbs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81c7c57a-4fbf-4ba4-b75d-8d11bd325bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exclusive_foreground_verbs = {\n",
    "    verb: count\n",
    "    for verb, count in foreground_verbs.items()\n",
    "    if count > 3 and verb not in background_verbs\n",
    "}\n",
    "\n",
    "exclusive_background_verbs = {\n",
    "    verb: count\n",
    "    for verb, count in background_verbs.items()\n",
    "    if count > 3 and verb not in foreground_verbs\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "971cc9ce-91fd-4332-905b-a8656f721c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclusive Foreground Verbs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reponer': 11,\n",
       " 'contestar': 16,\n",
       " 'oir': 15,\n",
       " 'acabar': 19,\n",
       " 'acercar': 7,\n",
       " 'pronunciar': 10,\n",
       " 'saltar': 4,\n",
       " 'lanzar': 7,\n",
       " 'llegar': 15,\n",
       " 'quedar': 26,\n",
       " 'matar': 6,\n",
       " 'entrar': 13,\n",
       " 'preguntar': 22,\n",
       " 'llenar': 7,\n",
       " 'exclamar': 21,\n",
       " 'poner': 18,\n",
       " 'creer': 4,\n",
       " 'tirar': 6,\n",
       " 'comenzar': 22,\n",
       " 'despertar': 10,\n",
       " 'ascender': 4,\n",
       " 'detener': 5,\n",
       " 'salir': 19,\n",
       " 'quemar': 5,\n",
       " 'observar': 9,\n",
       " 'gritar': 21,\n",
       " 'tender': 5,\n",
       " 'aparecer': 7,\n",
       " 'asomar': 6,\n",
       " 'ordenar': 5,\n",
       " 'caer': 17,\n",
       " 'volver': 28,\n",
       " 'regresar': 4,\n",
       " 'tomar': 10,\n",
       " 'coger': 6,\n",
       " 'alzar': 9,\n",
       " 'abrir': 10,\n",
       " 'responder': 18,\n",
       " 'levantar': 15,\n",
       " 'interrumpir': 4,\n",
       " 'inquirir': 6,\n",
       " 'sonreír': 7,\n",
       " 'encontrar': 9,\n",
       " 'sacar': 10,\n",
       " 'sentir': 8,\n",
       " 'reír': 4,\n",
       " 'suceder': 5,\n",
       " 'proseguir': 6,\n",
       " 'brillar': 6,\n",
       " 'clavar': 4,\n",
       " 'escapar': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Exclusive Foreground Verbs:\")\n",
    "exclusive_foreground_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b31f4d8-b9ce-482c-b28b-8429391d95eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclusive Background Verbs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'servir': 5,\n",
       " 'dormir': 8,\n",
       " 'vestir': 5,\n",
       " 'llevar': 12,\n",
       " 'estar': 16,\n",
       " 'seguir': 20,\n",
       " 'permanecer': 4,\n",
       " 'clamar': 12,\n",
       " 'tocar': 6,\n",
       " 'pedir': 8,\n",
       " 'meter': 8,\n",
       " 'ocurrir': 4,\n",
       " 'cubrir': 6,\n",
       " 'escuchar': 4,\n",
       " 'remover': 6,\n",
       " 'pensar': 5,\n",
       " 'reir': 4,\n",
       " 'maté': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Exclusive Background Verbs:\")\n",
    "exclusive_background_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33d502-f10f-4407-aee5-5b9a72753600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842ec565-3a9d-4ec0-a92b-7efaf8d6a415",
   "metadata": {},
   "source": [
    "<b> Task 6: Extraction of Key Events</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f374e4c5-085c-49d4-a746-124c68e543de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "num_chunks = 10\n",
    "chunk_size = len(sentences) // num_chunks\n",
    "remainder = len(sentences) % num_chunks\n",
    "\n",
    "print(chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee144c9-13ea-4ea8-a4ed-2325f79f8091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 has 193 sentences.\n",
      "Chunk 2 has 193 sentences.\n",
      "Chunk 3 has 193 sentences.\n",
      "Chunk 4 has 193 sentences.\n",
      "Chunk 5 has 193 sentences.\n",
      "Chunk 6 has 193 sentences.\n",
      "Chunk 7 has 193 sentences.\n",
      "Chunk 8 has 193 sentences.\n",
      "Chunk 9 has 192 sentences.\n",
      "Chunk 10 has 192 sentences.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunks = []\n",
    "start = 0\n",
    "for i in range(num_chunks):\n",
    "    end = start + chunk_size + (1 if i < remainder else 0)\n",
    "    chunks.append(sentences[start:end])\n",
    "    start = end\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1} has {len(chunk)} sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "827bffef-dfb3-47f3-b69c-cb773ebc1311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abrir',\n",
       " 'acabar',\n",
       " 'acercar',\n",
       " 'alzar',\n",
       " 'andar',\n",
       " 'aparecer',\n",
       " 'apurar',\n",
       " 'asomar',\n",
       " 'bajar',\n",
       " 'brillar',\n",
       " 'buscar',\n",
       " 'caer',\n",
       " 'cantar',\n",
       " 'clamar',\n",
       " 'coger',\n",
       " 'comenzar',\n",
       " 'conocer',\n",
       " 'contar',\n",
       " 'contestar',\n",
       " 'correr',\n",
       " 'cuadrar',\n",
       " 'cubrir',\n",
       " 'dar',\n",
       " 'decir',\n",
       " 'dejar',\n",
       " 'desaparecer',\n",
       " 'despertar',\n",
       " 'detener',\n",
       " 'dormir',\n",
       " 'echar',\n",
       " 'encontrar',\n",
       " 'entender',\n",
       " 'entrar',\n",
       " 'esperar',\n",
       " 'estar',\n",
       " 'exclamar',\n",
       " 'faltar',\n",
       " 'gritar',\n",
       " 'hablar',\n",
       " 'hacer',\n",
       " 'hundir',\n",
       " 'inquirir',\n",
       " 'ir',\n",
       " 'lanzar',\n",
       " 'levantar',\n",
       " 'llamar',\n",
       " 'llegar',\n",
       " 'llenar',\n",
       " 'llevar',\n",
       " 'matar',\n",
       " 'meter',\n",
       " 'observar',\n",
       " 'ofrecer',\n",
       " 'oir',\n",
       " 'ordenar',\n",
       " 'parecer',\n",
       " 'pasar',\n",
       " 'pedir',\n",
       " 'pensar',\n",
       " 'perder',\n",
       " 'poner',\n",
       " 'preguntar',\n",
       " 'pronunciar',\n",
       " 'proseguir',\n",
       " 'quedar',\n",
       " 'quemar',\n",
       " 'querer',\n",
       " 'remover',\n",
       " 'reponer',\n",
       " 'responder',\n",
       " 'robar',\n",
       " 'saber',\n",
       " 'sacar',\n",
       " 'salir',\n",
       " 'seguir',\n",
       " 'sentir',\n",
       " 'servir',\n",
       " 'sonreír',\n",
       " 'suceder',\n",
       " 'tender',\n",
       " 'tener',\n",
       " 'tirar',\n",
       " 'tocar',\n",
       " 'tomar',\n",
       " 'traer',\n",
       " 'venir',\n",
       " 'ver',\n",
       " 'vestir',\n",
       " 'vivir',\n",
       " 'volver'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_to_include = {verb for verb, count in\n",
    "                    verb_counter.items() if count >= 5}\n",
    "\n",
    "verbs_to_include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d978141-501f-4e66-9914-ff947722ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "  volver: log:  -2.23\n",
      "  vivir: log:  -0.92\n",
      "  vestir: log:  -0.51\n",
      "  ver: log:  -1.19\n",
      "  venir: log:  -1.50\n",
      "Chunk 2:\n",
      "  volver: log:  -1.54\n",
      "  vivir: log:  -0.51\n",
      "  ver: log:  -0.94\n",
      "  venir: log:  -1.64\n",
      "  tomar: log:  -0.69\n",
      "Chunk 3:\n",
      "  volver: log:  -1.95\n",
      "  vivir: log:  -1.61\n",
      "  vestir: log:  -1.61\n",
      "  ver: log:  -0.50\n",
      "  venir: log:  -1.39\n",
      "Chunk 4:\n",
      "  volver: log:  -3.33\n",
      "  vivir: log:  -1.61\n",
      "  ver: log:  -0.94\n",
      "  venir: log:  -2.20\n",
      "  traer: log:  -0.92\n",
      "Chunk 5:\n",
      "  volver: log:  -1.54\n",
      "  vivir: log:  -1.61\n",
      "  ver: log:  -0.74\n",
      "  venir: log:  -1.28\n",
      "  traer: log:  -1.20\n",
      "Chunk 6:\n",
      "  volver: log:  -1.39\n",
      "  vivir: log:  -1.61\n",
      "  ver: log:  -1.06\n",
      "  venir: log:  -1.79\n",
      "  traer: log:  -1.61\n",
      "Chunk 7:\n",
      "  volver: log:  -1.72\n",
      "  vestir: log:  -0.92\n",
      "  ver: log:  -0.83\n",
      "  venir: log:  -1.64\n",
      "  traer: log:  -1.20\n",
      "Chunk 8:\n",
      "  volver: log:  -1.95\n",
      "  vivir: log:  -1.61\n",
      "  vestir: log:  -0.92\n",
      "  ver: log:  -0.94\n",
      "  venir: log:  -1.97\n",
      "Chunk 9:\n",
      "  volver: log:  -1.72\n",
      "  ver: log:  -1.06\n",
      "  venir: log:  -2.48\n",
      "  traer: log:  -0.92\n",
      "  tomar: log:  -1.20\n",
      "Chunk 10:\n",
      "  volver: log:  -1.39\n",
      "  ver: log:  -1.34\n",
      "  venir: log:  -1.50\n",
      "  traer: log:  -2.30\n",
      "  tomar: log:  -1.20\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "prominent_verbs_per_chunk = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunk_verbs = []  \n",
    "    chunk_doc = model(\" \".join(chunk)) \n",
    "    \n",
    "    for sent in chunk_doc.sents:\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"VERB\":\n",
    "                chunk_verbs.append(token.lemma_)\n",
    "                \n",
    "\n",
    "    chunk_verb_counts = Counter(chunk_verbs)\n",
    "\n",
    "    log_ratios = {}\n",
    "    for verb, chunk_count in chunk_verb_counts.items():\n",
    "        if verb in verbs_to_include:\n",
    "            overall_count = verb_counter.get(verb, 0)  \n",
    "            log_ratio = math.log(chunk_count / overall_count) \n",
    "            log_ratios[verb] = log_ratio\n",
    "    \n",
    "    top_verbs = sorted(log_ratios.items(),  reverse=True)[:5]\n",
    "    prominent_verbs_per_chunk.append(top_verbs)\n",
    "\n",
    "for i, top_verbs in enumerate(prominent_verbs_per_chunk):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    for verb, log_ratio in top_verbs:\n",
    "        print(f\"  {verb}: log:  {log_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05039ec-fe6a-4e08-9074-524f2856dbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
